{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/furkan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/furkan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/furkan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/furkan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/furkan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/furkan/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Loaded model from disk\n",
      "WARNING:tensorflow:From /home/furkan/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:From /home/furkan/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:809: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import shutil\n",
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "import pytesseract\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "# Simple CNN model for CIFAR-10\n",
    "import keras\n",
    "from keras.layers import Dense,Dropout,Flatten, Activation,Conv1D,MaxPooling1D,LSTM,Embedding,Input,Conv2D\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n",
    "\n",
    "import keras_metrics\n",
    "K.common.set_image_dim_ordering('th')\n",
    "import tensorflow as tf\n",
    "# Plot ad hoc CIFAR10 instances\n",
    "from keras.datasets import cifar10\n",
    "from matplotlib import pyplot\n",
    "from scipy.misc import toimage\n",
    "\n",
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "@as_keras_metric\n",
    "def auc_pr(y_true, y_pred, curve='PR'):\n",
    "    return tf.metrics.auc(y_true, y_pred, curve=curve)\n",
    "\n",
    "# load data\n",
    "#(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "from IPython.display import Image\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('Json-modelV3.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"H5-modelV3.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', metrics = [auc_pr]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3072 into shape (32,32,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4de6970090bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#d = b[:,:,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#d = im.resize((32,32,3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 3072 into shape (32,32,1)"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "a = '/home/furkan/Desktop/ocrBuilding/l-1-lØ¯.jpg'\n",
    "im = PIL.Image.open(a)\n",
    "b = np.array(im.resize([32,32],PIL.Image.ANTIALIAS))\n",
    "d = b[:,:,:]\n",
    "#im = np.array(im)\n",
    "d = b.reshape((b.shape[0], b.shape[1], 1))\n",
    "\n",
    "#d = im.resize((32,32,3))\n",
    "c = model.predict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# The local path to our target image\n",
    "img_path = '/home/furkan/Desktop/latin/l-14-ls.jpg'\n",
    "\n",
    "# `img` is a PIL image of size 150x150\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "# `x` is a float32 Numpy array of shape (150, 150, 3)\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# We add a dimension to transform our array into a \"batch\"\n",
    "# of size (1, 150, 150, 3)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x /= 255\n",
    "\n",
    "# Finally we preprocess the batch\n",
    "# (this does channel-wise color normalization)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-102.942924, -102.942924, -102.942924, ..., -102.939   ,\n",
       "          -102.939   , -102.939   ],\n",
       "         [-102.942924, -102.942924, -102.942924, ..., -102.939   ,\n",
       "          -102.939   , -102.939   ],\n",
       "         [-102.942924, -102.942924, -102.942924, ..., -102.939   ,\n",
       "          -102.939   , -102.939   ],\n",
       "         ...,\n",
       "         [-102.942924, -102.942924, -102.942924, ..., -102.939   ,\n",
       "          -102.939   , -102.939   ],\n",
       "         [-102.942924, -102.942924, -102.942924, ..., -102.939   ,\n",
       "          -102.939   , -102.939   ],\n",
       "         [-102.942924, -102.942924, -102.942924, ..., -102.939   ,\n",
       "          -102.939   , -102.939   ]],\n",
       "\n",
       "        [[-115.78292 , -115.78292 , -115.78292 , ..., -115.779   ,\n",
       "          -115.779   , -115.779   ],\n",
       "         [-115.78292 , -115.78292 , -115.78292 , ..., -115.779   ,\n",
       "          -115.779   , -115.779   ],\n",
       "         [-115.78292 , -115.78292 , -115.78292 , ..., -115.779   ,\n",
       "          -115.779   , -115.779   ],\n",
       "         ...,\n",
       "         [-115.78292 , -115.78292 , -115.78292 , ..., -115.779   ,\n",
       "          -115.779   , -115.779   ],\n",
       "         [-115.78292 , -115.78292 , -115.78292 , ..., -115.779   ,\n",
       "          -115.779   , -115.779   ],\n",
       "         [-115.78292 , -115.78292 , -115.78292 , ..., -115.779   ,\n",
       "          -115.779   , -115.779   ]],\n",
       "\n",
       "        [[-122.68392 , -122.68392 , -122.68392 , ..., -122.68    ,\n",
       "          -122.68    , -122.68    ],\n",
       "         [-122.68392 , -122.68392 , -122.68392 , ..., -122.68    ,\n",
       "          -122.68    , -122.68    ],\n",
       "         [-122.68392 , -122.68392 , -122.68392 , ..., -122.68    ,\n",
       "          -122.68    , -122.68    ],\n",
       "         ...,\n",
       "         [-122.68392 , -122.68392 , -122.68392 , ..., -122.68    ,\n",
       "          -122.68    , -122.68    ],\n",
       "         [-122.68392 , -122.68392 , -122.68392 , ..., -122.68    ,\n",
       "          -122.68    , -122.68    ],\n",
       "         [-122.68392 , -122.68392 , -122.68392 , ..., -122.68    ,\n",
       "          -122.68    , -122.68    ]]]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape((150,150,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_1_input to have shape (150, 150, 3) but got array with shape (3, 150, 150)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-564c0c9b625a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_1_input to have shape (150, 150, 3) but got array with shape (3, 150, 150)"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "print('Predicted:', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
