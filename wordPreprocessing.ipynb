{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import shutil\n",
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "import pytesseract\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "# Simple CNN model for CIFAR-10\n",
    "import keras\n",
    "from keras.layers import Dense,Dropout,Flatten, Activation,Conv1D,MaxPooling1D,LSTM,Embedding,Input,Conv2D\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import sequence\n",
    "from keras import backend as K\n",
    "\n",
    "import keras_metrics\n",
    "K.common.set_image_dim_ordering('th')\n",
    "import tensorflow as tf\n",
    "# Plot ad hoc CIFAR10 instances\n",
    "from keras.datasets import cifar10\n",
    "from matplotlib import pyplot\n",
    "#import scipy.misc.toimage \n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "@as_keras_metric\n",
    "def auc_pr(y_true, y_pred, curve='PR'):\n",
    "    return tf.metrics.auc(y_true, y_pred, curve=curve)\n",
    "\n",
    "# load data\n",
    "#(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stages of Optical Character Recognition\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Stages of Optical Character Recognition\")\n",
    "Image(filename='/home/furkan/Desktop/Models/words/l-1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file =  r'/home/furkan/Desktop/Models/words/l-1.jpg'\n",
    "#file = r'output2/sample.jpg'\n",
    "image = PIL.Image.open(file)\n",
    "text = pytesseract.image_to_string(image,'ara')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "image/jpeg": {
       "height": 100,
       "width": 200
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file =  r'/home/furkan/Desktop/Models/words/l-1.jpg'\n",
    "\n",
    "im1 = cv2.imread(file, 0)\n",
    "im = cv2.imread(file)\n",
    "\n",
    "ret,thresh1 = cv2.threshold(im1,180,255,cv2.THRESH_BINARY_INV)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "dilated = cv2.dilate(thresh1,kernel,iterations = 2)\n",
    "contours, hierarchy = cv2.findContours(dilated,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cordinates = []\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    cordinates.append((x,y,w,h))\n",
    "    #bound the images\n",
    "    cv2.rectangle(im,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "\n",
    "#cv2.namedWindow('osmanlica22', cv2.WINDOW_NORMAL)\n",
    "cv2.imwrite('/home/furkan/Desktop/Models/changeWords/cl-1.jpg',im)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='/home/furkan/Desktop/Models/changeWords/cl-1.jpg',width=200,height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file, where you ant to store the data\n",
    "file = open('/home/furkan/Desktop/Models/cord/CordinatesImg1', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(cordinates, file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "image/jpeg": {
       "height": 200,
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im1 = cv2.imread('/home/furkan/Desktop/Models/words/l-1.jpg',0)\n",
    "im = cv2.imread('/home/furkan/Desktop/Models/words/l-1.jpg')\n",
    "\n",
    "ret,thresh1 = cv2.threshold(im1,180,278,cv2.THRESH_BINARY)\n",
    "contours, hierarchy = cv2.findContours(thresh1,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(im,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "i=0\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    if w>100 and h>100:\n",
    "        #save individual images\n",
    "        cv2.imwrite(str(i)+\".jpg\",thresh1[y:y+h,x:x+w])\n",
    "        i=i+1\n",
    "#cv2.namedWindow('osmanlica22', cv2.WINDOW_NORMAL)\n",
    "cv2.imwrite('/home/furkan/Desktop/Models/changeWords/chl-1.jpg',im)\n",
    "from IPython.display import Image\n",
    "Image(filename='/home/furkan/Desktop/Models/changeWords/chl-1.jpg',width=400,height=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b6ac25953528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# show annotated image and wait for keypress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# cv2.imshow(files[0], img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# read the image and get the dimensions\n",
    "img = cv2.imread('/home/furkan/Desktop/Models/words/l-1.jpg')\n",
    "h, w,_= img.shape # assumes color image\n",
    "\n",
    "# run tesseract, returning the bounding boxes\n",
    "boxes = pytesseract.image_to_boxes(img).split('\\n') # also include any config options you use\n",
    "# Box = list(map(lambda box:(box[:1],list(map(int,box[2:][:-2].split(' ')))),boxes))\n",
    "\n",
    "# draw the bounding boxes on the image\n",
    "for b in boxes:\n",
    "    b = b.split(' ')\n",
    "    img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)\n",
    "# show annotated image and wait for keypress\n",
    "# cv2.imshow(files[0], img)\n",
    "\n",
    "cv2.imwrite('exboxeImg1.jpg',img)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='exboxeImg1.jpg',width=400,height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
